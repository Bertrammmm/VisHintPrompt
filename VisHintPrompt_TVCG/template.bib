@inproceedings{shtedritski2023does,
  title={What does clip know about a red circle? visual prompt engineering for vlms},
  author={Shtedritski, Aleksandar and Rupprecht, Christian and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11987--11997},
  year={2023}
}

@inproceedings{lei-etal-2025-scaffolding,
    title = "Scaffolding Coordinates to Promote Vision-Language Coordination in Large Multi-Modal Models",
    author = "Lei, Xuanyu  and
      Yang, Zonghan  and
      Chen, Xinrui  and
      Li, Peng  and
      Liu, Yang",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.195/",
    pages = "2886--2903",
    abstract = "State-of-the-art Large Multi-Modal Models (LMMs) have demonstrated exceptional capabilities in vision-language tasks. Despite their advanced functionalities, the performances of LMMs are still limited in challenging scenarios that require complex reasoning with multiple levels of visual information. Existing prompting techniques for LMMs focus on either improving textual reasoning or leveraging tools for image preprocessing, lacking a simple and general visual prompting scheme to promote vision-language coordination in LMMs. In this work, we propose SCAFFOLD prompting that scaffolds coordinates to promote vision-language coordination. Specifically, SCAFFOLD overlays a dot matrix within the image as visual information anchors and leverages multi-dimensional coordinates as textual positional references. Extensive experiments on a wide range of challenging vision-language tasks demonstrate the superiority of SCAFFOLD over the textual Chain-of-Thought prompting."
}

@inproceedings{cuarbune2024chart,
  title={Chart-based reasoning: Transferring capabilities from llms to vlms},
  author={C{\u{a}}rbune, Victor and Mansoor, Hassan and Liu, Fangyu and Aralikatte, Rahul and Baechler, Gilles and Chen, Jindong and Sharma, Abhanshu},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={989--1004},
  year={2024}
}

@article{han2023chartllama,
  title={Chartllama: A multimodal llm for chart understanding and generation},
  author={Han, Yucheng and Zhang, Chi and Chen, Xin and Yang, Xu and Wang, Zhibin and Yu, Gang and Fu, Bin and Zhang, Hanwang},
  journal={arXiv preprint arXiv:2311.16483},
  year={2023}
}

@inproceedings{tang2023vistext,
  title={Vistext: A benchmark for semantically rich chart captioning},
  author={Tang, Benny and Boggust, Angie and Satyanarayan, Arvind},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7268--7298},
  year={2023}
}

@Misc{Grinstein2002InformationVisualizationVisual,
  author       = {Grinstein, Georges and Keim, Daniel and Ward, Matthew},
  howpublished = {IEEE Visualization Course \#1 Notes},
  month        = oct,
  title        = {Information visualization, visual data mining, and its application to drug design},
  year         = {2002},
  url          = {http://vis.computer.org/vis2002/program/tutorials/tutorial_01_abstract.html},
}

@Article{Isenberg2017Vispubdata.orgMetadataCollection,
  author  = {Isenberg, Petra and Heimerl, Florian and Koch, Steffen and Isenberg, Tobias and Xu, Panpan and Stolper, Chad and Sedlmair, Michael and Chen, Jian and M{\"o}ller, Torsten and Stasko, John},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {{vispubdata.org}: a metadata collection about {IEEE} visualization ({VIS}) publications},
  year    = {2017},
  volume  = {23},
  doi     = {10.1109/TVCG.2016.2615308},
  series  = {TVCG},
}

@MastersThesis{Kindlmann1999SemiAutomaticGeneration,
  author  = {Kindlmann, Gordon},
  school  = {Cornell University},
  title   = {Semi-automatic generation of transfer functions for direct volume rendering},
  year    = {1999},
  address = {USA},
  url     = {http://www.graphics.cornell.edu/pubs/1999/Kin99.html},
}

@Manual{Kitware2003VisualizationToolkitUsers,
  title  = {{The Visualization Toolkit} user's guide},
  author = {{Kitware, Inc.}},
  month  = jan,
  year   = {2003},
  url    = {http://www.kitware.com/publications/item/view/1269},
}

@PhdThesis{Levoy1989DisplaySurfacesVolume,
  author  = {Levoy, Marc},
  school  = {University of North Carolina at Chapel Hill},
  title   = {Display of surfaces from volume data},
  year    = {1989},
  address = {USA},
  url     = {http://www.cs.unc.edu/techreports/89-022.pdf},
}

@Article{Lorensen1987MarchingCubesHigh,
  author  = {Lorensen, William E. and Cline, Harvey E.},
  journal = {SIGGRAPH Computer Graphics},
  title   = {{M}arching {C}ubes: A high resolution {3D} surface construction algorithm},
  year    = {1987},
  month   = aug,  
  number  = {4},
  pages   = {163--169},
  volume  = {21},
  doi     = {10.1145/37402.37422},
}

@Article{Max1995OpticalModelsDirect,
  author  = {Max, Nelson},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {Optical models for direct volume rendering},
  year    = {1995},
  month   = jun,
  number  = {2},
  pages   = {99--108},
  volume  = {1},
  doi     = {10.1109/2945.468400},
  series  = {TVCG},
}

@InProceedings{Nielson1991AsymptoticDeciderRemoving,
  author    = {Nielson, Gregory M. and Hamann, Bernd},
  booktitle = {Proc.\ Visualization},
  title     = {The asymptotic decider: removing the ambiguity in marching cubes},
  year      = {1991},
  pages     = {83--91},
  series    = {VIS},
  doi       = {10.1109/VISUAL.1991.175782},
}

@Book{Ware2004InformationVisualizationPerception,
  author    = {Ware, Colin},
  publisher = {Morgan Kaufmann Publishers Inc.},
  title     = {Information visualization: perception for design},
  year      = {2004},
  address   = {San Francisco},
  edition   = {2\textsuperscript{nd}},
  doi       = {10.1016/B978-155860819-1/50001-7},
}

@article{qwen2-vl,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}


@ARTICLE{ChartInsighter,
  author={Wang, Fen and Wang, Bomiao and Shu, Xueli and Liu, Zhen and Shao, Zekai and Liu, Chao and Chen, Siming},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={ChartInsighter: An Approach for Mitigating Hallucination in Time-Series Chart Summary Generation With a Benchmark Dataset}, 
  year={2025},
  volume={31},
  number={6},
  pages={3733-3745},
  keywords={Market research;Cognition;Accuracy;Benchmark testing;Semantics;Data mining;Reliability;Large language models;Internet;Data visualization;Chart summarization;hallucination;large language model;benchmark;time-series data visualization},
  doi={10.1109/TVCG.2025.3567122}}



@Article{Wyvill1986DataStructureSoft,
  author  = {Wyvill, Geoff and McPheeters, Craig and Wyvill, Brian},
  journal = {The Visual Computer},
  title   = {Data structure for \emph{soft} objects},
  year    = {1986},
  month   = aug,
  number  = {4},
  pages   = {227--234},
  volume  = {2},
  doi     = {10.1007/BF01900346},
}


@inproceedings{ChartGemma,
    title = "{C}hart{G}emma: Visual Instruction-tuning for Chart Reasoning in the Wild",
    author = "Masry, Ahmed  and
      Thakkar, Megh  and
      Bajaj, Aayush  and
      Kartha, Aaryaman  and
      Hoque, Enamul  and
      Joty, Shafiq",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven  and
      Darwish, Kareem  and
      Agarwal, Apoorv",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics: Industry Track",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-industry.54/",
    pages = "625--643"
}

@article{visrefinstuning,
  author={Zeng, Xingchen and Lin, Haichuan and Ye, Yilin and Zeng, Wei},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning}, 
  year={2024},
  pages={1-11},
  doi={10.1109/TVCG.2024.3456159}
}

@ARTICLE{ChartKG,
  author={Zhou, Zhiguang and Wang, Haoxuan and Zhao, Zhengqing and Zheng, Fengling and Wang, Yongheng and Chen, Wei and Wang, Yong},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={ChartKG: A Knowledge-Graph-Based Representation for Chart Images}, 
  year={2025},
  volume={31},
  number={9},
  pages={5854-5868},
  doi={10.1109/TVCG.2024.3476508}}



@article{ChartCap,
  title={ChartCap: Mitigating Hallucination of Dense Chart Captioning},
  author={Lim, Junyoung and Ahn, Jaewoo and Kim, Gunhee},
  journal={arXiv preprint arXiv:2508.03164},
  year={2025}
}

@article{ChartSketcher,
  title={ChartSketcher: Reasoning with Multimodal Feedback and Reflection for Chart Understanding},
  author={Huang, Muye and Zhang, Lingling and Ma, Jie and Lai, Han and Xu, Fangzhi and Li, Yifei and Wu, Wenjun and Wu, Yaqiang and Liu, Jun},
  journal={arXiv preprint arXiv:2505.19076},
  year={2025}
}

@article{CHOPINLLM,
  title={On pre-training of multimodal language models customized for chart understanding},
  author={Fan, Wan-Cyuan and Chen, Yen-Chun and Liu, Mengchen and Yuan, Lu and Sigal, Leonid},
  journal={arXiv preprint arXiv:2407.14506},
  year={2024}
}

@article{Chart-r1,
  title={Chart-r1: Chain-of-thought supervision and reinforcement for advanced chart reasoner},
  author={Chen, Lei and Zhao, Xuanle and Zeng, Zhixiong and Huang, Jing and Zhong, Yufeng and Ma, Lin},
  journal={arXiv preprint arXiv:2507.15509},
  year={2025}
}

@article{PretrainingMLLM,
  title={On pre-training of multimodal language models customized for chart understanding},
  author={Fan, Wan-Cyuan and Chen, Yen-Chun and Liu, Mengchen and Yuan, Lu and Sigal, Leonid},
  journal={arXiv preprint arXiv:2407.14506},
  year={2024}
}

@article{FromPixels2Insights,
    author = {Huang, Kung-Hsiang and Chan, Hou Pong and Fung, May and Qiu, Haoyi and Zhou, Mingyang and Joty, Shafiq and Chang, Shih-Fu and Ji, Heng},
    title = {From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models},
    year = {2024},
    issue_date = {May 2025},
    journal={IEEE Transactions on Knowledge and Data Engineering}, 
    publisher = {IEEE Educational Activities Department},
    address = {USA},
    volume = {37},
    number = {5},
    issn = {1041-4347},
    url = {https://doi.org/10.1109/TKDE.2024.3513320},
    doi = {10.1109/TKDE.2024.3513320},
    month = dec,
    pages = {2550–2568},
    numpages = {19}
}

@ARTICLE{SC2LC,
  author={Ying, Lu and Wang, Yun and Li, Haotian and Dou, Shuguang and Zhang, Haidong and Jiang, Xinyang and Qu, Huamin and Wu, Yingcai},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Reviving Static Charts Into Live Charts}, 
  year={2025},
  volume={31},
  number={8},
  pages={4314-4328},
  doi={10.1109/TVCG.2024.3397004}
}

@article{Gemini2.5,
  title={Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities},
  author={Comanici, Gheorghe and Bieber, Eric and Schaekermann, Mike and Pasupat, Ice and Sachdeva, Noveen and Dhillon, Inderjit and Blistein, Marcel and Ram, Ori and Zhang, Dan and Rosen, Evan and others},
  journal={arXiv preprint arXiv:2507.06261},
  year={2025}
}

@misc{GPT5,
  author = {OpenAI},
  title = {Introducing GPT-5},
  year = {2025},
  howpublished = {\url{https://openai.com/index/introducing-gpt-5/}}
}

@article{GLM4.5v,
  title   = {GLM-4.5V and GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning},
  author  = {{GLM-V Team}},
  journal = {arXiv preprint arXiv:2507.01006},
  year    = {2025}
}

@article{Qwen2.5-vl,
  title={Qwen2.5-vl technical report},
  author={Bai, Shuai and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Song, Sibo and Dang, Kai and Wang, Peng and Wang, Shijie and Tang, Jun and others},
  journal={arXiv preprint arXiv:2502.13923},
  year={2025}
}


@article{ChartX,
  title={ChartX \& ChartVLM: A Versatile Benchmark and Foundation Model for Complicated Chart Reasoning},
  author={Renqiu Xia and Bo Zhang and Hancheng Ye and Xiangchao Yan and Qi Liu and Hongbin Zhou and Zijun Chen and Min Dou and Botian Shi and Junchi Yan and Yu Qiao},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.12185},
  url={https://api.semanticscholar.org/CorpusID:267751223}
}

@article{HoughTransform,
author = {Duda, Richard O. and Hart, Peter E.},
title = {Use of the Hough transformation to detect lines and curves in pictures},
year = {1972},
issue_date = {Jan. 1972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/361237.361242},
doi = {10.1145/361237.361242},
abstract = {Hough has proposed an interesting and computationally efficient procedure for detecting lines in pictures. This paper points out that the use of angle-radius rather than slope-intercept parameters simplifies the computation further. It also shows how the method can be used for more general curve fitting, and gives alternative interpretations that explain the source of its efficiency.},
journal = {Commun. ACM},
month = jan,
pages = {11–15},
numpages = {5},
keywords = {Hough transformation, colinear points, curve detection, line detection, pattern recognition, picture processing, point-line transformation}
}

@inproceedings{ChartQA,
    title = "{C}hart{QA}: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning",
    author = "Masry, Ahmed  and
      Long, Do Xuan  and
      Tan, Jia Qing  and
      Joty, Shafiq  and
      Hoque, Enamul",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.177/",
    doi = "10.18653/v1/2022.findings-acl.177",
    pages = "2263--2279"
}

@INPROCEEDINGS{PlotQA,
  author={Methani, Nitesh and Ganguly, Pritha and Khapra, Mitesh M. and Kumar, Pratyush},
  booktitle={2020 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={PlotQA: Reasoning over Scientific Plots}, 
  year={2020},
  volume={},
  number={},
  pages={1516-1525},
  keywords={Vocabulary;Cognition;Bars;Numerical models;Optical character recognition software;Data mining;Image color analysis},
  doi={10.1109/WACV45572.2020.9093523}
}



@inproceedings{ChartQAPro,
    title = "{C}hart{QAP}ro: A More Diverse and Challenging Benchmark for Chart Question Answering",
    author = "Masry, Ahmed  and
      Islam, Mohammed Saidul  and
      Ahmed, Mahir  and
      Bajaj, Aayush  and
      Kabir, Firoz  and
      Kartha, Aaryaman  and
      Laskar, Md Tahmid Rahman  and
      Rahman, Mizanur  and
      Rahman, Shadikur  and
      Shahmohammadi, Mehrad  and
      Thakkar, Megh  and
      Parvez, Md Rizwan  and
      Hoque, Enamul  and
      Joty, Shafiq",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2025",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-acl.978/",
    doi = "10.18653/v1/2025.findings-acl.978",
    pages = "19123--19151",
    ISBN = "979-8-89176-256-5"
}

@inproceedings{Chartquestionanswering,
  title={Chart question answering: State of the art and future directions},
  author={Hoque, Enamul and Kavehzadeh, Parsa and Masry, Ahmed},
  booktitle={Computer Graphics Forum},
  volume={41},
  number={3},
  pages={555--572},
  year={2022},
  organization={Wiley Online Library}
}

@inproceedings{Deplot,
    title = "{D}e{P}lot: One-shot visual language reasoning by plot-to-table translation",
    author = "Liu, Fangyu  and
      Eisenschlos, Julian  and
      Piccinno, Francesco  and
      Krichene, Syrine  and
      Pang, Chenxi  and
      Lee, Kenton  and
      Joshi, Mandar  and
      Chen, Wenhu  and
      Collier, Nigel  and
      Altun, Yasemin",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.660/",
    doi = "10.18653/v1/2023.findings-acl.660",
    pages = "10381--10399"
}

@inproceedings{EvoChart,
    author = {Huang, Muye and Lai, Han and Zhang, Xinyu and Wu, Wenjun and Ma, Jie and Zhang, Lingling and Liu, Jun},
    title = {EvoChart: a benchmark and a self-training approach towards real-world chart understanding},
    year = {2025},
    isbn = {978-1-57735-897-8},
    publisher = {AAAI Press},
    url = {https://doi.org/10.1609/aaai.v39i4.32383},
    doi = {10.1609/aaai.v39i4.32383},
    articleno = {410},
    numpages = {9},
    booktitle = {Proceedings of the Thirty-Ninth AAAI Conference on Artificial Intelligence},
    series = {AAAI'25/IAAI'25/EAAI'25}
}

@inproceedings{Answercharts,
    author = {Kim, Dae Hyun and Hoque, Enamul and Agrawala, Maneesh},
    title = {Answering Questions about Charts and Generating Visual Explanations},
    year = {2020},
    isbn = {9781450367080},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3313831.3376467},
    doi = {10.1145/3313831.3376467},
    booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
    pages = {1–13},
    numpages = {13},
    keywords = {explainable ai, question answering, visualization},
    location = {Honolulu, HI, USA},
    series = {CHI '20}
}

@inproceedings{Chart-to-Text,
    title = "Chart-to-Text: A Large-Scale Benchmark for Chart Summarization",
    author = "Kantharaj, Shankar  and
      Leong, Rixie Tiffany  and
      Lin, Xiang  and
      Masry, Ahmed  and
      Thakkar, Megh  and
      Hoque, Enamul  and
      Joty, Shafiq",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.277/",
    doi = "10.18653/v1/2022.acl-long.277",
    pages = "4005--4023"
}

@inproceedings{CharXiv,
    author = {Wang, Zirui and Xia, Mengzhou and He, Luxi and Chen, Howard and Liu, Yitao and Zhu, Richard and Liang, Kaiqu and Wu, Xindi and Liu, Haotian and Malladi, Sadhika and Chevalier, Alexis and Arora, Sanjeev and Chen, Danqi},
    title = {CharXiv: charting gaps in realistic chart understanding in multimodal LLMs},
    year = {2025},
    isbn = {9798331314385},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    booktitle = {Proceedings of the 38th International Conference on Neural Information Processing Systems},
    articleno = {3609},
    numpages = {129},
    location = {Vancouver, BC, Canada},
    series = {NIPS '24}
}

@inproceedings{NLDataset,
    author = {Ko, Hyung-Kwon and Jeon, Hyeon and Park, Gwanmo and Kim, Dae Hyun and Kim, Nam Wook and Kim, Juho and Seo, Jinwook},
    title = {Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models},
    year = {2024},
    isbn = {9798400703300},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3613904.3642943},
    doi = {10.1145/3613904.3642943},
    booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
    articleno = {843},
    numpages = {22},
    keywords = {Vega-Lite, data visualization, framework, large language models, natural language datasets, natural language interfaces},
    location = {Honolulu, HI, USA},
    series = {CHI '24}
}

@inproceedings{ChartMoE,
    title={ChartMoE: Mixture of Diversely Aligned Expert Connector for Chart Understanding},
    author={Zhengzhuo Xu and Bowen Qu and Yiyan Qi and SiNan Du and Chengjin Xu and Chun Yuan and Jian Guo},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=o5TsWTUSeF}
}


@inproceedings{QwenChart,
    title = "Instruction-tuned {Q}wen{C}hart for Chart Question Answering",
    author = "Ventura, Viviana  and
      Kleybolte, Lukas Amadeus  and
      Zarcone, Alessandra",
    editor = "Ghosal, Tirthankar  and
      Mayr, Philipp  and
      Singh, Amanpreet  and
      Naik, Aakanksha  and
      Rehm, Georg  and
      Freitag, Dayne  and
      Li, Dan  and
      Schimmler, Sonja  and
      De Waard, Anita",
    booktitle = "Proceedings of the Fifth Workshop on Scholarly Document Processing (SDP 2025)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.sdp-1.22/",
    doi = "10.18653/v1/2025.sdp-1.22",
    pages = "240--251",
    ISBN = "979-8-89176-265-7"
}
@inproceedings{ChartAssistant,
    title = "{C}hart{A}ssistant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning",
    author = "Meng, Fanqing  and
      Shao, Wenqi  and
      Lu, Quanfeng  and
      Gao, Peng  and
      Zhang, Kaipeng  and
      Qiao, Yu  and
      Luo, Ping",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.463/",
    doi = "10.18653/v1/2024.findings-acl.463",
    pages = "7775--7803"
}

@inproceedings{MMC,
    title = "{MMC}: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning",
    author = "Liu, Fuxiao  and
      Wang, Xiaoyang  and
      Yao, Wenlin  and
      Chen, Jianshu  and
      Song, Kaiqiang  and
      Cho, Sangwoo  and
      Yacoob, Yaser  and
      Yu, Dong",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.70/",
    doi = "10.18653/v1/2024.naacl-long.70",
    pages = "1287--1310"
}

@InProceedings{Scatteract,
    author="Cliche, Mathieu
    and Rosenberg, David
    and Madeka, Dhruv
    and Yee, Connie",
    editor="Ceci, Michelangelo
    and Hollm{\'e}n, Jaakko
    and Todorovski, Ljup{\v{c}}o
    and Vens, Celine
    and D{\v{z}}eroski, Sa{\v{s}}o",
    title="Scatteract: Automated Extraction of Data from Scatter Plots",
    booktitle="Machine Learning and Knowledge Discovery in Databases",
    year="2017",
    publisher="Springer International Publishing",
    address="Cham",
    pages="135--150",
    isbn="978-3-319-71249-9"
}

@InProceedings{DVQA,
    author = {Kafle, Kushal and Price, Brian and Cohen, Scott and Kanan, Christopher},
    title = {DVQA: Understanding Data Visualizations via Question Answering},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2018},
    series = {CVPR '18}
}

@INPROCEEDINGS{ChartOCR,
  author={Luo, Junyu and Li, Zekun and Wang, Jinpeng and Lin, Chin-Yew},
  booktitle={2021 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={ChartOCR: Data Extraction from Charts Images via a Deep Hybrid Framework}, 
  year={2021},
  volume={},
  number={},
  pages={1916-1924},
  doi={10.1109/WACV48630.2021.00196}
}

@inproceedings{Pix2struct,
  title={Pix2struct: Screenshot parsing as pretraining for visual language understanding},
  author={Lee, Kenton and Joshi, Mandar and Turc, Iulia Raluca and Hu, Hexiang and Liu, Fangyu and Eisenschlos, Julian Martin and Khandelwal, Urvashi and Shaw, Peter and Chang, Ming-Wei and Toutanova, Kristina},
  booktitle={International Conference on Machine Learning},
  pages={18893--18912},
  year={2023},
  organization={PMLR},
    series = {ICML '23}
}

@inproceedings{MatCha,
    title = "{M}at{C}ha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering",
    author = "Liu, Fangyu  and
      Piccinno, Francesco  and
      Krichene, Syrine  and
      Pang, Chenxi  and
      Lee, Kenton  and
      Joshi, Mandar  and
      Altun, Yasemin  and
      Collier, Nigel  and
      Eisenschlos, Julian",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.714/",
    doi = "10.18653/v1/2023.acl-long.714",
    pages = "12756--12770"
}

@inproceedings{NovaChart,
    author = {Hu, Linmei and Wang, Duokang and Pan, Yiming and Yu, Jifan and Shao, Yingxia and Feng, Chong and Nie, Liqiang},
    title = {NovaChart: A Large-scale Dataset towards Chart Understanding and Generation of Multimodal Large Language Models},
    year = {2024},
    isbn = {9798400706868},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3664647.3680790},
    doi = {10.1145/3664647.3680790},
    booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
    pages = {3917–3925},
    numpages = {9},
    keywords = {chart generation, chart understanding, multimodal large language model},
    location = {Melbourne VIC, Australia},
    series = {MM '24}
}

@inproceedings{UniChart,
    title = "{U}ni{C}hart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning",
    author = "Masry, Ahmed  and
      Kavehzadeh, Parsa  and
      Do, Xuan Long  and
      Hoque, Enamul  and
      Joty, Shafiq",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.906/",
    doi = "10.18653/v1/2023.emnlp-main.906",
    pages = "14662--14684",
    series = {EMNLP '23}
}

@inproceedings{ChartT5,
    title = "Enhanced Chart Understanding via Visual Language Pre-training on Plot Table Pairs",
    author = "Zhou, Mingyang  and
      Fung, Yi  and
      Chen, Long  and
      Thomas, Christopher  and
      Ji, Heng  and
      Chang, Shih-Fu",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.85/",
    doi = "10.18653/v1/2023.findings-acl.85",
    pages = "1314--1326"
}

@inproceedings{Onechart,
    title={Onechart: Purify the chart structural extraction via one auxiliary token},
    author={Chen, Jinyue and Kong, Lingyu and Wei, Haoran and Liu, Chenglong and Ge, Zheng and Zhao, Liang and Sun, Jianjian and Han, Chunrui and Zhang, Xiangyu},
    booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
    pages={147--155},
    year={2024}
}

@inproceedings{ReVision,
    author = {Savva, Manolis and Kong, Nicholas and Chhajta, Arti and Fei-Fei, Li and Agrawala, Maneesh and Heer, Jeffrey},
    title = {ReVision: automated classification, analysis and redesign of chart images},
    year = {2011},
    isbn = {9781450307161},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2047196.2047247},
    doi = {10.1145/2047196.2047247},
    booktitle = {Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology},
    pages = {393–402},
    numpages = {10},
    keywords = {visualization, redesign, information extraction, computer vision, chart understanding},
    location = {Santa Barbara, California, USA},
    series = {UIST '11}
}

@inproceedings{ChartSense,
    author = {Jung, Daekyoung and Kim, Wonjae and Song, Hyunjoo and Hwang, Jeong-in and Lee, Bongshin and Kim, Bohyoung and Seo, Jinwook},
    title = {ChartSense: Interactive Data Extraction from Chart Images},
    year = {2017},
    isbn = {9781450346559},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3025453.3025957},
    doi = {10.1145/3025453.3025957},
    booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
    pages = {6706–6717},
    numpages = {12},
    keywords = {chart classification, chart recognition, data extraction, deep learning, mixed-initiative interaction},
    location = {Denver, Colorado, USA},
    series = {CHI '17}
}

@InProceedings{CACHED,
    author="Yan, Pengyu
    and Ahmed, Saleem
    and Doermann, David",
    editor="Fink, Gernot A.
    and Jain, Rajiv
    and Kise, Koichi
    and Zanibbi, Richard",
    title="Context-Aware Chart Element Detection",
    booktitle="Document Analysis and Recognition - ICDAR 2023",
    year="2023",
    publisher="Springer Nature Switzerland",
    address="Cham",
    pages="218--233",
    isbn="978-3-031-41676-7",
    series = {ICDAR '23}
}

@inproceedings{ChartInstruct,
    title = "{C}hart{I}nstruct: Instruction Tuning for Chart Comprehension and Reasoning",
    author = "Masry, Ahmed  and
      Shahmohammadi, Mehrad  and
      Parvez, Md Rizwan  and
      Hoque, Enamul  and
      Joty, Shafiq",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.619/",
    doi = "10.18653/v1/2024.findings-acl.619",
    pages = "10387--10409"
}

@inproceedings{lvlms,
    title = "Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning",
    author = "Huang, Kung-Hsiang  and
      Zhou, Mingyang and
      Chan, Hou Pong  and
      Fung, Yi R. and
      Wang, Zhenhailong and
      Zhang, Lingyu and
      Chang, Shih-Fu and
      Ji, Heng",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.85",
    doi = "10.18653/v1/2023.findings-acl.85",
    pages = "1314--1326",
    series = {ACL '24}
}    

@inproceedings{EffectTrainingData,
    title={Effective Training Data Synthesis for Improving MLLM Chart Understanding},
     author={Yang, Yuwei and Zhang, Zeyu and Hou, Yunzhong and Li, Zhuowan and Liu, Gaowen and Payani, Ali and Ting, Yuan-Sen and Zheng, Liang},
    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year={2025},
    series = {ICCV '25}
 }

@inproceedings{TinyChart,
    title = "{T}iny{C}hart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging",
    author = "Zhang, Liang  and
      Hu, Anwen  and
      Xu, Haiyang  and
      Yan, Ming  and
      Xu, Yichen  and
      Jin, Qin  and
      Zhang, Ji  and
      Huang, Fei",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.112/",
    doi = "10.18653/v1/2024.emnlp-main.112",
    pages = "1882--1898"
}

@inproceedings{VisualCoT,
    author = {Shao, Hao and Qian, Shengju and Xiao, Han and Song, Guanglu and Zong, Zhuofan and Wang, Letian and Liu, Yu and Li, Hongsheng},
    title = {Visual CoT: advancing multi-modal language models with a comprehensive dataset and benchmark for chain-of-thought reasoning},
    year = {2025},
    isbn = {9798331314385},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    booktitle = {Proceedings of the 38th International Conference on Neural Information Processing Systems},
    articleno = {275},
    numpages = {31},
    location = {Vancouver, BC, Canada},
    series = {NIPS '24}
}

@InProceedings{DetToolChain,
    author="Wu, Yixuan
    and Wang, Yizhou
    and Tang, Shixiang
    and Wu, Wenhao
    and He, Tong
    and Ouyang, Wanli
    and Torr, Philip
    and Wu, Jian",
    editor="Leonardis, Ale{\v{s}}
    and Ricci, Elisa
    and Roth, Stefan
    and Russakovsky, Olga
    and Sattler, Torsten
    and Varol, G{\"u}l",
    title="DetToolChain: A New Prompting Paradigm to Unleash Detection Ability of MLLM",
    booktitle="Computer Vision -- ECCV 2024",
    year="2025",
    publisher="Springer Nature Switzerland",
    address="Cham",
    pages="164--182"
}

@inproceedings{ChartThinker,
    title = "{C}hart{T}hinker: A Contextual Chain-of-Thought Approach to Optimized Chart Summarization",
    author = "Liu, Mengsha  and
      Chen, Daoyuan  and
      Li, Yaliang  and
      Fang, Guian  and
      Shen, Ying",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.273/",
    pages = "3057--3074"
}

@inproceedings{ChartInsights,
    title = "{C}hart{I}nsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering",
    author = "Wu, Yifan  and
      Yan, Lutao  and
      Shen, Leixian  and
      Wang, Yunhai  and
      Tang, Nan  and
      Luo, Yuyu",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.710/",
    doi = "10.18653/v1/2024.findings-emnlp.710",
    pages = "12174--12200"
}

@inproceedings{VProChart,
    author = {Huang, Muye and Zhang, Lingling and Han, Lai and Wu, Wenjun and Zhang, Xinyu and Liu, Jun},
    title = {VProChart: answering chart question through visual perception alignment agent and programmatic solution reasoning},
    year = {2025},
    isbn = {978-1-57735-897-8},
    publisher = {AAAI Press},
    url = {https://doi.org/10.1609/aaai.v39i4.32384},
    doi = {10.1609/aaai.v39i4.32384},
    booktitle = {Proceedings of the Thirty-Ninth AAAI Conference on Artificial Intelligence and Thirty-Seventh Conference on Innovative Applications of Artificial Intelligence and Fifteenth Symposium on Educational Advances in Artificial Intelligence},
    articleno = {411},
    numpages = {8},
    series = {AAAI'25/IAAI'25/EAAI'25}
}


@InProceedings{Panavas2022JuvenileGraphicalPerception,
  author    = {Panavas, Liudas and Worth, Amy E. and Crnovrsanin, Tarik and Sathyamurthi, Tejas and Cordes, Sara and Borkin, Michelle A. and Dunne, Cody},
  booktitle = {Proc. 2022 CHI Conference on Human Factors in Computing Systems},
  title     = {Juvenile graphical perception: A comparison between children and adults},
  year      = {2022},
  series    = {CHI},
  articleno = {138},
  doi       = {10.1145/3491102.3501893},
  numpages  = {14},
}

@Comment{jabref-meta: databaseType:bibtex;}
