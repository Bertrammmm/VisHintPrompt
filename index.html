<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="VisHintPrompt: A Visual Hint Prompting Strategy for Numerical Inference from Charts">
  <meta name="description" content="A scaffolded visual hint prompting strategy for fine-grained numerical inference from charts using pretrained MLLMs, without requiring additional training.">
  <meta name="keywords" content="chart understanding, multimodal large language models, visual prompting, data inference, information visualization, MLLM, chart question answering">
  <meta name="author" content="Fengling Zheng, Yongle Peng, Zi Rong, Chenyun Cai, Yumeng He, Dekun Qian, Zhiguang Zhou, Yigang Wang, Yong Wang">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Hangzhou Dianzi University">
  <meta property="og:title" content="VisHintPrompt: A Visual Hint Prompting Strategy for Numerical Inference from Charts">
  <meta property="og:description" content="A scaffolded visual hint prompting strategy for fine-grained numerical inference from charts using pretrained MLLMs, without requiring additional training.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="VisHintPrompt - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Fengling Zheng">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Chart Understanding">
  <meta property="article:tag" content="Multimodal Large Language Models">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <meta name="twitter:title" content="VisHintPrompt: A Visual Hint Prompting Strategy for Numerical Inference from Charts">
  <meta name="twitter:description" content="A scaffolded visual hint prompting strategy for fine-grained numerical inference from charts using pretrained MLLMs, without requiring additional training.">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="VisHintPrompt - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="VisHintPrompt: A Visual Hint Prompting Strategy for Numerical Inference from Charts">
  <meta name="citation_author" content="Zheng, Fengling">
  <meta name="citation_author" content="Peng, Yongle">
  <meta name="citation_author" content="Rong, Zi">
  <meta name="citation_author" content="Cai, Chenyun">
  <meta name="citation_author" content="He, Yumeng">
  <meta name="citation_author" content="Qian, Dekun">
  <meta name="citation_author" content="Zhou, Zhiguang">
  <meta name="citation_author" content="Wang, Yigang">
  <meta name="citation_author" content="Wang, Yong">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="IEEE Transactions on Visualization and Computer Graphics">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>VisHintPrompt: A Visual Hint Prompting Strategy for Numerical Inference from Charts | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "VisHintPrompt: A Visual Hint Prompting Strategy for Numerical Inference from Charts",
    "description": "A scaffolded visual hint prompting strategy for fine-grained numerical inference from charts using pretrained MLLMs, without requiring additional training.",
    "author": [
      {
        "@type": "Person",
        "name": "Fengling Zheng",
        "affiliation": {
          "@type": "Organization",
          "name": "Hangzhou Dianzi University"
        }
      },
      {
        "@type": "Person",
        "name": "Yongle Peng",
        "affiliation": {
          "@type": "Organization",
          "name": "Hangzhou Dianzi University"
        }
      },
      {
        "@type": "Person",
        "name": "Zi Rong",
        "affiliation": {
          "@type": "Organization",
          "name": "Hangzhou Dianzi University"
        }
      },
      {
        "@type": "Person",
        "name": "Chenyun Cai",
        "affiliation": {
          "@type": "Organization",
          "name": "Hangzhou Dianzi University"
        }
      },
      {
        "@type": "Person",
        "name": "Yumeng He",
        "affiliation": {
          "@type": "Organization",
          "name": "University of Southern California"
        }
      },
      {
        "@type": "Person",
        "name": "Dekun Qian",
        "affiliation": {
          "@type": "Organization",
          "name": "Hangzhou Dianzi University"
        }
      },
      {
        "@type": "Person",
        "name": "Zhiguang Zhou",
        "affiliation": {
          "@type": "Organization",
          "name": "Hangzhou Dianzi University"
        }
      },
      {
        "@type": "Person",
        "name": "Yigang Wang",
        "affiliation": {
          "@type": "Organization",
          "name": "Hangzhou Dianzi University"
        }
      },
      {
        "@type": "Person",
        "name": "Yong Wang",
        "affiliation": {
          "@type": "Organization",
          "name": "Nanyang Technological University"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "IEEE Transactions on Visualization and Computer Graphics"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["Chart Understanding", "Multimodal Large Language Models", "Visual Prompting", "Data Inference", "Information Visualization"],
    "abstract": "Numerical inference from charts underpins many visualization tasks, including chart question answering and chart redesign. Although many chart-specific models have been developed for numerical extraction, their reliance on the chart types and visual encodings represented in training data limits their generalizability. Modern Multimodal Large Language Models (MLLMs) possess competitive general-purpose visual understanding, offering the potential for numerical inference without additional training. Yet how to reliably elicit such fine-grained numerical inference from pretrained MLLMs via visual prompting remains largely unexplored. To address this gap, we propose VisHintPrompt, a scaffolded visual hint prompting strategy grounded in the explicit extraction of axis priors from both Cartesian and polar charts. VisHintPrompt elicits the latent numerical inference abilities of MLLMs by progressively narrowing the search region. It supplies structured visual cues that guide the model toward accurate quantitative interpretation. The strategy consists of three coordinated components: Axis-aware Grid Enhancement, which extracts fine-grained axis priors and further exposes them as structure-aligned grids; Iterative Visual Feedback, which overlays alignment cues derived from intermediate predictions to enhance the next prediction; and Progressive Zoom-in Refinement, which enlarges the region of interest and applies progressive grid densification to enhance local detail for precise value estimation. VisHintPrompt is visual-centric and applies to both Cartesian charts (e.g., bar, scatterplot) and polar charts (e.g., pie, radar). Experiments across diverse chart types on both proprietary and open-source MLLMs demonstrate consistent improvements over standard prompting. Quantitative and qualitative analyses, along with ablation studies, validate the effectiveness and essential role of each component. These results underscore the broad applicability of VisHintPrompt in enabling reliable and more accurate numerical inference from charts.",
    "citation": "@article{VisHintPrompt2024, title={VisHintPrompt: A Visual Hint Prompting Strategy for Numerical Inference from Charts}, author={Zheng, Fengling and Peng, Yongle and Rong, Zi and Cai, Chenyun and He, Yumeng and Qian, Dekun and Zhou, Zhiguang and Wang, Yigang and Wang, Yong}, journal={IEEE Transactions on Visualization and Computer Graphics}, year={2024}}",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Chart Understanding"
      },
      {
        "@type": "Thing", 
        "name": "Multimodal Large Language Models"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Hangzhou Dianzi University",
    "url": "https://www.hdu.edu.cn",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": []
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()" title="Close" aria-label="Close dropdown">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- TODO: Replace with your lab's related works -->
        <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank" rel="noopener">
          <div class="work-info">
            <!-- TODO: Replace with actual paper title -->
            <h5>Paper Title 1</h5>
            <!-- TODO: Replace with brief description -->
            <p>Brief description of the work and its main contribution.</p>
            <!-- TODO: Replace with venue and year -->
            <span class="work-venue">Conference/Journal 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <!-- TODO: Add more related works or remove extra items -->
        <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank" rel="noopener">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank" rel="noopener">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">VisHintPrompt: A Visual Hint Prompting Strategy for Numerical Inference from Charts</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="mailto:fenglingzheng@hdu.edu.cn" target="_blank" rel="noopener">Fengling Zheng</a>,</span>
              <span class="author-block">
                <a href="mailto:22330236@hdu.edu.cn" target="_blank" rel="noopener">Yongle Peng</a>,</span>
              <span class="author-block">
                <a href="mailto:rongzizi@hdu.edu.cn" target="_blank" rel="noopener">Zi Rong</a>,</span>
              <span class="author-block">
                <a href="mailto:23280129@hdu.edu.cn" target="_blank" rel="noopener">Chenyun Cai</a>,</span>
              <span class="author-block">
                <a href="mailto:heyumeng@usc.edu" target="_blank" rel="noopener">Yumeng He</a>,</span>
              <span class="author-block">
                <a href="mailto:qiandekun@hdu.edu.cn" target="_blank" rel="noopener">Dekun Qian</a>,</span>
              <span class="author-block">
                <a href="mailto:zhgzhou@hdu.edu.cn" target="_blank" rel="noopener">Zhiguang Zhou</a>,</span>
              <span class="author-block">
                <a href="mailto:yigang.wang@hdu.edu.cn" target="_blank" rel="noopener">Yigang Wang</a>,</span>
              <span class="author-block">
                <a href="http://yong-wang.org" target="_blank" rel="noopener">Yong Wang</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Hangzhou Dianzi University, Nanyang Technological University, University of Southern California<br>IEEE Transactions on Visualization and Computer Graphics (TVCG) 2024</span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank" rel="noopener"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank" rel="noopener"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank" rel="noopener"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank" rel="noopener"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TODO: Replace with your teaser video -->
      <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <!-- TODO: Add your video file path here -->
        <source src="static/videos/banner_video.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        VisHintPrompt: A scaffolded visual hint prompting strategy for fine-grained numerical inference from charts using pretrained MLLMs, without requiring additional training. The method progressively narrows the search region and supplies structured visual cues to guide accurate quantitative interpretation.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Numerical inference from charts underpins many visualization tasks, including chart question answering and chart redesign. Although many chart-specific models have been developed for numerical extraction, their reliance on the chart types and visual encodings represented in training data limits their generalizability. Modern Multimodal Large Language Models (MLLMs) possess competitive general-purpose visual understanding, offering the potential for numerical inference without additional training. Yet how to reliably elicit such fine-grained numerical inference from pretrained MLLMs via visual prompting remains largely unexplored. To address this gap, we propose <strong>VisHintPrompt</strong>, a scaffolded visual hint prompting strategy grounded in the explicit extraction of axis priors from both Cartesian and polar charts. VisHintPrompt elicits the latent numerical inference abilities of MLLMs by progressively narrowing the search region. It supplies structured visual cues that guide the model toward accurate quantitative interpretation.
          </p>
          <p>
            The strategy consists of three coordinated components: <em>Axis-aware Grid Enhancement</em>, which extracts fine-grained axis priors and further exposes them as structure-aligned grids; <em>Iterative Visual Feedback</em>, which overlays alignment cues derived from intermediate predictions to enhance the next prediction; and <em>Progressive Zoom-in Refinement</em>, which enlarges the region of interest and applies progressive grid densification to enhance local detail for precise value estimation. VisHintPrompt is visual-centric and applies to both Cartesian charts (e.g., bar, scatterplot) and polar charts (e.g., pie, radar). Experiments across diverse chart types on both proprietary and open-source MLLMs demonstrate consistent improvements over standard prompting. Quantitative and qualitative analyses, along with ablation studies, validate the effectiveness and essential role of each component. These results underscore the broad applicability of VisHintPrompt in enabling reliable and more accurate numerical inference from charts.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="VisHintPrompt_TVCG/figs/teaser.png" alt="VisHintPrompt overview: A visual hint prompt engineering framework for data inference from charts" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Overview of VisHintPrompt, a visual hint prompt engineering framework for data inference from charts. The method operates in three stages: (1) axis-aware grid enhancement, (2) visual feedback prompting, and (3) progressive zoom-in refinement.
        </h2>
      </div>
      <div class="item">
        <img src="VisHintPrompt_TVCG/figs/Introduction.png" alt="Examples of scatterplot data inference with an MLLM" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          An illustrative example of scatterplot data inference using an MLLM with or without visual hints (i.e., the grid here). Grid hints substantially improve extraction performance.
        </h2>
      </div>
      <div class="item">
        <img src="VisHintPrompt_TVCG/figs/pipeline.png" alt="VisHintPrompt pipeline" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          The pipeline of VisHintPrompt showing the three coordinated components working together for accurate numerical inference.
        </h2>
     </div>
     <div class="item">
      <img src="VisHintPrompt_TVCG/figs/grid-refine.png" alt="Grid refinement process" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Progressive grid densification process that enhances local detail for precise value estimation.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- TODO: Replace with your YouTube video ID -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen title="VisHintPrompt Video Presentation"></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <!-- TODO: Add poster image for better preview -->
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <!-- TODO: Replace with your poster PDF -->
      <iframe src="static/pdfs/sample.pdf" width="100%" height="550" title="Paper Poster">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{VisHintPrompt2024,
  title={VisHintPrompt: A Visual Hint Prompting Strategy for Numerical Inference from Charts},
  author={Zheng, Fengling and Peng, Yongle and Rong, Zi and Cai, Chenyun and He, Yumeng and Qian, Dekun and Zhou, Zhiguang and Wang, Yigang and Wang, Yong},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank" rel="noopener">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank" rel="noopener">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license noopener" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
